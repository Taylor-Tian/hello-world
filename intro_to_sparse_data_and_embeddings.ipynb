{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_sparse_data_and_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mNCLhxsXyOIS",
        "eQS5KQzBybTY",
        "copyright-notice"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taylor-Tian/hello-world/blob/master/intro_to_sparse_data_and_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright-notice"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "copyright-notice2",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTaAdgy3LS8W",
        "colab_type": "text"
      },
      "source": [
        " # 稀疏数据和嵌入简介\n",
        "\n",
        "**学习目标：**\n",
        "* 将影评字符串数据转换为稀疏特征矢量\n",
        "* 使用稀疏特征矢量实现情感分析线性模型\n",
        "* 通过将数据投射到二维空间的嵌入来实现情感分析 DNN 模型\n",
        "* 将嵌入可视化，以便查看模型学到的词语之间的关系\n",
        "\n",
        "在此练习中，我们将探讨稀疏数据，并使用影评文本数据（来自 [ACL 2011 IMDB 数据集](http://ai.stanford.edu/~amaas/data/sentiment/)）进行嵌入。这些数据已被处理成 `tf.Example` 格式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKGtmwNosU8",
        "colab_type": "text"
      },
      "source": [
        " ## 设置\n",
        "\n",
        "我们导入依赖项并下载训练数据和测试数据。[`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) 中包含一个文件下载和缓存工具，我们可以用它来检索数据集。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWqDqFFL_NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "train_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W7aZ9qspZVj",
        "colab_type": "text"
      },
      "source": [
        " ## 构建情感分析模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jieA0k_NLS8a",
        "colab_type": "text"
      },
      "source": [
        " 我们根据这些数据训练一个情感分析模型，以预测某条评价总体上是*好评*（标签为 1）还是*差评*（标签为 0）。\n",
        "\n",
        "为此，我们会使用*词汇表*（即我们预计将在数据中看到的每个术语的列表），将字符串值 `terms` 转换为特征矢量。在本练习中，我们创建了侧重于一组有限术语的小型词汇表。其中的大多数术语明确表示是*好评*或*差评*，但有些只是因为有趣而被添加进来。\n",
        "\n",
        "词汇表中的每个术语都与特征矢量中的一个坐标相对应。为了将样本的字符串值 `terms` 转换为这种矢量格式，我们按以下方式处理字符串值：如果该术语没有出现在样本字符串中，则坐标值将为 0；如果出现在样本字符串中，则值为 1。未出现在该词汇表中的样本中的术语将被弃用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HSfklfnLS8b",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*我们当然可以使用更大的词汇表，而且有创建此类词汇表的专用工具。此外，我们可以添加少量的 OOV（未收录词汇）分桶，您可以在其中对词汇表中未包含的术语进行哈希处理，而不仅仅是弃用这些术语。我们还可以使用__特征哈希__法对每个术语进行哈希处理，而不是创建显式词汇表。这在实践中很有效，但却不具备可解读性（这对本练习非常实用）。如需了解处理此类词汇表的工具，请参阅 tf.feature_column 模块。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvoa2HyDtgqe",
        "colab_type": "text"
      },
      "source": [
        " ## 构建输入管道"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O20vMEOurDol",
        "colab_type": "text"
      },
      "source": [
        " 首先，我们来配置输入管道，以将数据导入 TensorFlow 模型中。我们可以使用以下函数来解析训练数据和测试数据（格式为 [TFRecord](https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data)），然后返回一个由特征和相应标签组成的字典。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxNIEniPq2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return  {'terms':terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXhTeeYMrp-l",
        "colab_type": "text"
      },
      "source": [
        " 为了确认函数是否能正常运行，我们为训练数据构建一个 `TFRecordDataset`，并使用上述函数将数据映射到特征和标签。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF4YWXR0Omt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "271c761b-35b4-49fa-8a16-681d4d7d4a58"
      },
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)\n",
        "\n",
        "ds"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUoMvK-9tVXP",
        "colab_type": "text"
      },
      "source": [
        " 运行以下单元，以从训练数据集中获取第一个样本。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6QE2DWRUc4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "f1c0a3d0-444f-451a-e902-c3698044b6cb"
      },
      "source": [
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()\n",
        "sess.run(n)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'terms': array([b'but', b'it', b'does', b'have', b'some', b'good', b'action',\n",
              "         b'and', b'a', b'plot', b'that', b'is', b'somewhat', b'interesting',\n",
              "         b'.', b'nevsky', b'acts', b'like', b'a', b'body', b'builder',\n",
              "         b'and', b'he', b'isn', b\"'\", b't', b'all', b'that', b'attractive',\n",
              "         b',', b'in', b'fact', b',', b'imo', b',', b'he', b'is', b'ugly',\n",
              "         b'.', b'(', b'his', b'acting', b'skills', b'lack', b'everything',\n",
              "         b'!', b')', b'sascha', b'is', b'played', b'very', b'well', b'by',\n",
              "         b'joanna', b'pacula', b',', b'but', b'she', b'needed', b'more',\n",
              "         b'lines', b'than', b'she', b'was', b'given', b',', b'her',\n",
              "         b'character', b'needed', b'to', b'be', b'developed', b'.',\n",
              "         b'there', b'are', b'way', b'too', b'many', b'men', b'in', b'this',\n",
              "         b'story', b',', b'there', b'is', b'zero', b'romance', b',', b'too',\n",
              "         b'much', b'action', b',', b'and', b'way', b'too', b'dumb', b'of',\n",
              "         b'an', b'ending', b'.', b'it', b'is', b'very', b'violent', b'.',\n",
              "         b'i', b'did', b'however', b'love', b'the', b'scenery', b',',\n",
              "         b'this', b'movie', b'takes', b'you', b'all', b'over', b'the',\n",
              "         b'world', b',', b'and', b'that', b'is', b'a', b'bonus', b'.', b'i',\n",
              "         b'also', b'liked', b'how', b'it', b'had', b'some', b'stuff',\n",
              "         b'about', b'the', b'mafia', b'in', b'it', b',', b'not', b'too',\n",
              "         b'much', b'or', b'too', b'little', b',', b'but', b'enough',\n",
              "         b'that', b'it', b'got', b'my', b'attention', b'.', b'the',\n",
              "         b'actors', b'needed', b'to', b'be', b'more', b'handsome', b'.',\n",
              "         b'.', b'.', b'the', b'biggest', b'problem', b'i', b'had', b'was',\n",
              "         b'that', b'nevsky', b'was', b'just', b'too', b'normal', b',',\n",
              "         b'not', b'sexy', b'enough', b'.', b'i', b'think', b'for', b'most',\n",
              "         b'guys', b',', b'sascha', b'will', b'be', b'hot', b'enough', b',',\n",
              "         b'but', b'for', b'us', b'ladies', b'that', b'are', b'fans', b'of',\n",
              "         b'action', b',', b'nevsky', b'just', b'doesn', b\"'\", b't', b'cut',\n",
              "         b'it', b'.', b'overall', b',', b'this', b'movie', b'was', b'fine',\n",
              "         b',', b'i', b'didn', b\"'\", b't', b'love', b'it', b'nor', b'did',\n",
              "         b'i', b'hate', b'it', b',', b'just', b'found', b'it', b'to', b'be',\n",
              "         b'another', b'normal', b'action', b'flick', b'.'], dtype=object)},\n",
              " array([0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBU39UeFty9S",
        "colab_type": "text"
      },
      "source": [
        " 现在，我们构建一个正式的输入函数，可以将其传递给 TensorFlow Estimator 对象的 `train()` 方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_C5-ueNYIn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input_fn that parses the tf.Examples from the given files,\n",
        "# and split them into features and targets.\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "  \n",
        "  # Same code as above; create a dataset and map features and labels.\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  # Our feature data is variable-length, so we pad and batch\n",
        "  # each field of the dataset structure to whatever size is necessary.     \n",
        "  ds = ds.padded_batch(25, ds.output_shapes)\n",
        "  \n",
        "  ds = ds.repeat(num_epochs)\n",
        "\n",
        "  \n",
        "  # Return the next batch of data.\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y170tVlrLS8c",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 1：使用具有稀疏输入和显式词汇表的线性模型\n",
        "\n",
        "对于我们的第一个模型，我们将使用 50 个信息性术语来构建 [`LinearClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) 模型；始终从简单入手！\n",
        "\n",
        "以下代码将为我们的术语构建特征列。[`categorical_column_with_vocabulary_list`](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list) 函数可使用“字符串-特征矢量”映射来创建特征列。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5gdxuWsvPcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 50 informative terms that compose our model vocabulary. \n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTiDwyorwd3P",
        "colab_type": "text"
      },
      "source": [
        " 接下来，我们将构建 `LinearClassifier`，在训练集中训练该模型，并在评估集中对其进行评估。阅读上述代码后，运行该模型以了解其效果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYKKpGLqLS8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "b1c78767-805f-4513-8013-6622a1626d79"
      },
      "source": [
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [ terms_feature_column ]\n",
        "\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.78796\n",
            "accuracy_baseline 0.5\n",
            "auc 0.87175834\n",
            "auc_precision_recall 0.86344934\n",
            "average_loss 0.45166332\n",
            "label/mean 0.5\n",
            "loss 11.291583\n",
            "precision 0.7758449\n",
            "prediction/mean 0.49083182\n",
            "recall 0.80992\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.78388\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8694564\n",
            "auc_precision_recall 0.86094743\n",
            "average_loss 0.45319209\n",
            "label/mean 0.5\n",
            "loss 11.329802\n",
            "precision 0.77327687\n",
            "prediction/mean 0.489313\n",
            "recall 0.80328\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ubn9gULS8g",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 2：使用深度神经网络 (DNN) 模型\n",
        "\n",
        "上述模型是一个线性模型，效果非常好。但是，我们可以使用 DNN 模型实现更好的效果吗？\n",
        "\n",
        "我们将 `LinearClassifier` 切换为 [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier)。运行以下单元，看看您的模型效果如何。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcgOPfEALS8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "27d9a973-dcd8-4ba0-bb31-d433485f4b7a"
      },
      "source": [
        "##################### Here's what we changed ##################################\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000)\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1)\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([test_path]),\n",
        "    steps=1)\n",
        "\n",
        "  print(\"Test set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.64\n",
            "accuracy_baseline 0.52\n",
            "auc 0.798077\n",
            "auc_precision_recall 0.8255533\n",
            "average_loss 0.5083965\n",
            "label/mean 0.48\n",
            "loss 12.709913\n",
            "precision 0.6363636\n",
            "prediction/mean 0.4540152\n",
            "recall 0.5833333\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.8\n",
            "accuracy_baseline 0.52\n",
            "auc 0.8397436\n",
            "auc_precision_recall 0.85059726\n",
            "average_loss 0.44060507\n",
            "label/mean 0.52\n",
            "loss 11.015127\n",
            "precision 0.78571427\n",
            "prediction/mean 0.45261508\n",
            "recall 0.84615386\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZz68luxLS8j",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 3：在 DNN 模型中使用嵌入\n",
        "\n",
        "在此任务中，我们将使用嵌入列来实现 DNN 模型。嵌入列会将稀疏数据作为输入，并返回一个低维度密集矢量作为输出。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliRzhvJLS8k",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*从计算方面而言，embedding_column 通常是用于在稀疏数据中训练模型最有效的选项。在此练习末尾的[可选部分](#scrollTo=XDMlGgRfKSVz)，我们将更深入地讨论使用 `embedding_column` 与 `indicator_column` 之间的实现差异，以及如何在这两者之间做出权衡。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-as3PtALS8l",
        "colab_type": "text"
      },
      "source": [
        " 在下面的代码中，执行以下操作：\n",
        "\n",
        "* 通过将数据投射到二维空间的 `embedding_column` 来为模型定义特征列（如需详细了解 `embedding_column` 的函数签名，请参阅相关 [TF 文档](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column)）。\n",
        "* 定义符合以下规范的 `DNNClassifier`：\n",
        "  * 具有两个隐藏层，每个包含 20 个单元\n",
        "  * 采用学习速率为 0.1 的 AdaGrad 优化方法\n",
        "  * `gradient_clip_norm 值为 5.0`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlPZ-Q9bLS8m",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*在实践中，我们可能会将数据投射到 2 维以上（比如 50 或 100）的空间中。但就目前而言，2 维是比较容易可视化的维数。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNCLhxsXyOIS",
        "colab_type": "text"
      },
      "source": [
        " ### 提示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L67xYD7hLS8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's a example code snippet you might use to define the feature columns:\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv1UBsJxyV37",
        "colab_type": "text"
      },
      "source": [
        " ### 完成以下代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PG_yhNGLS8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4442878b-0207-4437-de45-e3cae3c6e1fc"
      },
      "source": [
        "########################## YOUR CODE HERE ######################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(\n",
        "    categorical_column=[tf.feature_column.indicator_column(terms_feature_column)],\n",
        "    dimension=2,\n",
        "    combiner='mean',\n",
        "    initializer=None,\n",
        "    ckpt_to_load_from=None,\n",
        "    tensor_name_in_ckpt=None,\n",
        "    max_norm=None,\n",
        "    trainable=True\n",
        ")\n",
        "feature_columns = [tf.feature_column.indicator_column(terms_feature_column)]\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=feature_columns, #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")  \n",
        "################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.78588\n",
            "accuracy_baseline 0.5\n",
            "auc 0.87409174\n",
            "auc_precision_recall 0.86703956\n",
            "average_loss 0.4510784\n",
            "label/mean 0.5\n",
            "loss 11.27696\n",
            "precision 0.79966456\n",
            "prediction/mean 0.46398872\n",
            "recall 0.76288\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.781\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8718193\n",
            "auc_precision_recall 0.8647819\n",
            "average_loss 0.45346567\n",
            "label/mean 0.5\n",
            "loss 11.336641\n",
            "precision 0.79603875\n",
            "prediction/mean 0.46401387\n",
            "recall 0.7556\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQS5KQzBybTY",
        "colab_type": "text"
      },
      "source": [
        " ### 解决方案\n",
        "\n",
        "点击下方即可查看解决方案。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xOdYeQydi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "fb4c9254-c2c9-4b42-af64-c2e82e41a83e"
      },
      "source": [
        "########################## SOLUTION CODE ########################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "#################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.78468\n",
            "accuracy_baseline 0.5\n",
            "auc 0.86780006\n",
            "auc_precision_recall 0.8568278\n",
            "average_loss 0.4544556\n",
            "label/mean 0.5\n",
            "loss 11.361391\n",
            "precision 0.7843388\n",
            "prediction/mean 0.4895133\n",
            "recall 0.78528\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.7808\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8672123\n",
            "auc_precision_recall 0.855281\n",
            "average_loss 0.45549327\n",
            "label/mean 0.5\n",
            "loss 11.387332\n",
            "precision 0.7835676\n",
            "prediction/mean 0.48790005\n",
            "recall 0.77592\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHnnVtzLS8w",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 4：确信模型中确实存在嵌入\n",
        "\n",
        "上述模型使用了 `embedding_column`，而且似乎很有效，但这并没有让我们了解到内部发生的情形。我们如何检查该模型确实在内部使用了嵌入？\n",
        "\n",
        "首先，我们来看看该模型中的张量："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1jNgLdQLS8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "2036cf12-6611-4e56-f0c5-5bfab7a303ae"
      },
      "source": [
        "classifier.get_variable_names()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dnn/hiddenlayer_0/bias',\n",
              " 'dnn/hiddenlayer_0/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_0/kernel',\n",
              " 'dnn/hiddenlayer_0/kernel/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/bias',\n",
              " 'dnn/hiddenlayer_1/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/kernel',\n",
              " 'dnn/hiddenlayer_1/kernel/t_0/Adagrad',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights/t_0/Adagrad',\n",
              " 'dnn/logits/bias',\n",
              " 'dnn/logits/bias/t_0/Adagrad',\n",
              " 'dnn/logits/kernel',\n",
              " 'dnn/logits/kernel/t_0/Adagrad',\n",
              " 'global_step']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl4-VctMLS8z",
        "colab_type": "text"
      },
      "source": [
        " 好的，我们可以看到这里有一个嵌入层：`'dnn/input_from_feature_columns/input_layer/terms_embedding/...'`。（顺便说一下，有趣的是，该层可以与模型的其他层一起训练，就像所有隐藏层一样。）\n",
        "\n",
        "嵌入层的形状是否正确？请运行以下代码来查明。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFxyQUiLS80",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*在我们的示例中，嵌入是一个矩阵，可让我们将一个 50 维矢量投射到 2 维空间。*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cAqw9pfOIKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8798e291-684f-4ee2-cb95-42052a1c4f16"
      },
      "source": [
        "for  i in classifier.get_variable_names():\n",
        "  print(classifier.get_variable_value(i).shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20,)\n",
            "(20,)\n",
            "(2, 20)\n",
            "(2, 20)\n",
            "(20,)\n",
            "(20,)\n",
            "(20, 20)\n",
            "(20, 20)\n",
            "(50, 2)\n",
            "(50, 2)\n",
            "(1,)\n",
            "(1,)\n",
            "(20, 1)\n",
            "(20, 1)\n",
            "()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xMbpcEjLS80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0736e98-9051-42a6-8c58-4f300748b5cc"
      },
      "source": [
        "classifier.get_variable_value('dnn/hiddenlayer_0/bias/t_0/Adagrad').shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLCIogjLS82",
        "colab_type": "text"
      },
      "source": [
        " 花些时间来手动检查各个层及其形状，以确保一切都按照您预期的方式互相连接。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkKAaRWDLS83",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 5：检查嵌入\n",
        "\n",
        "现在，我们来看看实际嵌入空间，并了解术语最终所在的位置。请执行以下操作：\n",
        "1. 运行以下代码来查看我们在**任务 3** 中训练的嵌入。一切最终是否如您所预期的那样？\n",
        "\n",
        "2. 重新运行**任务 3** 中的代码来重新训练该模型，然后再次运行下面的嵌入可视化。哪些保持不变？哪些发生了变化？\n",
        "\n",
        "3. 最后，仅使用 10 步来重新训练该模型（这将产生一个糟糕的模型）。再次运行下面的嵌入可视化。您现在看到了什么？为什么？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4NNu7KqLS84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b1c122a2-85f3-4650-a4a7-dda5ec89ade6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "embedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')\n",
        "\n",
        "for term_index in range(len(informative_terms)):\n",
        "  # Create a one-hot encoding for our term.  It has 0s everywhere, except for\n",
        "  # a single 1 in the coordinate that corresponds to that term.\n",
        "  term_vector = np.zeros(len(informative_terms))\n",
        "  term_vector[term_index] = 1\n",
        "  # We'll now project that one-hot vector into the embedding space.\n",
        "  embedding_xy = np.matmul(term_vector, embedding_matrix)\n",
        "  plt.text(embedding_xy[0],\n",
        "           embedding_xy[1],\n",
        "           informative_terms[term_index])\n",
        "\n",
        "# Do a little setup to make sure the plot displays nicely.\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
        "plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.show() "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWThO5IwxZuE4kTPGmIX7fz1narUw+haBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUb3L7pqLS86",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 6：尝试改进模型的效果\n",
        "\n",
        "看看您能否优化该模型以改进其效果。您可以尝试以下几种做法：\n",
        "\n",
        "* **更改超参数**或**使用其他优化工具**，比如 Adam（通过遵循这些策略，您的准确率可能只会提高一两个百分点）。\n",
        "* **向 `informative_terms` 中添加其他术语。**此数据集有一个完整的词汇表文件，其中包含 30716 个术语，您可以在以下位置找到该文件：https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt 您可以从该词汇表文件中挑选出其他术语，也可以通过 `categorical_column_with_vocabulary_file` 特征列使用整个词汇表文件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-b3BqXvLS86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4eec64a-f87a-4ade-be98-7c3006e7e811"
      },
      "source": [
        "# Download the vocabulary file.\n",
        "terms_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt'\n",
        "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt\n",
            "253952/253538 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbJlwW5LS8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4b1e6c07-5f7b-4776-cc40-230b966174ee"
      },
      "source": [
        "# Create a feature column from \"terms\", using a full vocabulary file.\n",
        "informative_terms = None\n",
        "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
        "  # Convert it to a set first to remove duplicates.\n",
        "  informative_terms = list(set(f.read().split()))\n",
        "  \n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", \n",
        "                                                                                 vocabulary_list=informative_terms)\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[10,10],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.53836\n",
            "accuracy_baseline 0.5\n",
            "auc 0.61412364\n",
            "auc_precision_recall 0.6104963\n",
            "average_loss 0.68802375\n",
            "label/mean 0.5\n",
            "loss 17.200594\n",
            "precision 0.6795208\n",
            "prediction/mean 0.48008993\n",
            "recall 0.1452\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.5332\n",
            "accuracy_baseline 0.5\n",
            "auc 0.6051756\n",
            "auc_precision_recall 0.60244507\n",
            "average_loss 0.68856287\n",
            "label/mean 0.5\n",
            "loss 17.214073\n",
            "precision 0.6555472\n",
            "prediction/mean 0.47978458\n",
            "recall 0.13992\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew3kwGM-LS9B",
        "colab_type": "text"
      },
      "source": [
        " ## 总结\n",
        "\n",
        "我们可能获得了比我们原来的线性模型更好且具有嵌入的 DNN 解决方案，但线性模型也相当不错，而且训练速度快得多。线性模型的训练速度之所以更快，是因为它们没有太多要更新的参数或要反向传播的层。\n",
        "\n",
        "在有些应用中，线性模型的速度可能非常关键，或者从质量的角度来看，线性模型可能完全够用。在其他领域，DNN 提供的额外模型复杂性和能力可能更重要。在定义模型架构时，请记得要充分探讨您的问题，以便知道自己所处的情形。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MquXy9zLS9B",
        "colab_type": "text"
      },
      "source": [
        " ### *可选内容：*在 `embedding_column` 与 `indicator_column` 之间进行权衡\n",
        "\n",
        "从概念上讲，在训练 `LinearClassifier` 或 `DNNClassifier` 时，需要根据实际情况使用稀疏列。TF 提供了两个选项：`embedding_column` 或 `indicator_column`。\n",
        "\n",
        "在训练 LinearClassifier（如**任务 1** 中所示）时，系统在后台使用了 `embedding_column`。正如**任务 2** 中所示，在训练 `DNNClassifier` 时，您必须明确选择 `embedding_column` 或 `indicator_column`。本部分通过一个简单的示例讨论了这两者之间的区别，以及如何在二者之间进行权衡。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_3XuZ_LLS9C",
        "colab_type": "text"
      },
      "source": [
        " 假设我们的稀疏数据包含 `\"great\"`、`\"beautiful\"` 和 `\"excellent\"` 这几个值。由于我们在此处使用的词汇表大小为 $V = 50$，因此第一层中的每个单元（神经元）的权重将为 50。我们用 $s$ 表示稀疏输入中的项数。对于此示例稀疏数据，$s = 3$。对于具有 $V$ 个可能值的输入层，带有 $d$ 个单元的隐藏层需要运行一次“矢量 - 矩阵”乘法运算：$(1 \\times V) * (V \\times d)$。此运算会产生 $O(V * d)$ 的计算成本。请注意，此成本与隐藏层中的权重数成正比，而与 $s$ 无关。\n",
        "\n",
        "如果输入使用 [`indicator_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column) 进行了独热编码（长度为 $V$ 的布尔型矢量，存在用 1 表示，其余则为 0），这表示很多零进行了相乘和相加运算。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7mR4Wa2LS9C",
        "colab_type": "text"
      },
      "source": [
        " 当我们通过使用大小为 $d$ 的 [`embedding_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) 获得完全相同的结果时，我们将仅查询与示例输入中存在的 3 个特征 `\"great\"`、`\"beautiful\"` 和 `\"excellent\"` 相对应的嵌入并将这三个嵌入相加：$(1 \\times d) + (1 \\times d) + (1 \\times d)$。由于不存在的特征的权重在“矢量-矩阵”乘法中与 0 相乘，因此对结果没有任何影响；而存在的特征的权重在“矢量-矩阵”乘法中与 1 相乘。因此，将通过嵌入查询获得的权重相加会获得与“矢量-矩阵”乘法相同的结果。\n",
        "\n",
        "当使用嵌入时，计算嵌入查询是一个 $O(s * d)$ 计算；从计算方面而言，它比稀疏数据中的 `indicator_column` 的 $O(V * d)$ 更具成本效益，因为 $s$ 远远小于 $V$。（请注意，这些嵌入是临时学习的结果。在任何指定的训练迭代中，都是当前查询的权重。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZ9qf0kLS9D",
        "colab_type": "text"
      },
      "source": [
        " 正如我们在**任务 3** 中看到的，通过在训练 `DNNClassifier` 过程中使用 `embedding_column`，我们的模型学习了特征的低维度表示法，其中点积定义了一个针对目标任务的相似性指标。在本例中，影评中使用的相似术语（例如 `\"great\"` 和 `\"excellent\"`）在嵌入空间中彼此之间距离较近（即具有较大的点积），而相异的术语（例如 `\"great\"` 和 `\"bad\"`）在嵌入空间中彼此之间距离较远（即具有较小的点积）。"
      ]
    }
  ]
}